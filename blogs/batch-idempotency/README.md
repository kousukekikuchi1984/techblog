## Introduction

本記事では、ある実プロジェクトで設計したOLTP系の大規模バッチ処理について、その設計思想と背景、実装上の工夫、トレードオフなどを記録します。

対象となるデータは不可逆かつ時間制約のあるもので、処理ミスが許されない環境下にあります。この記事が、同様の状況に直面しているエンジニアやアーキテクトの参考になれば幸いです。

## Requirements

### こちらのシステムについて

- 会員管理をしている基盤
- ユーザー数はかなり多い
- OLTP 
- 検証用のチームがいる


### データや制約について
- データ生成元はメインフレームで動く重厚なシステムで、日次で全銀フォーマットに沿ったCSVファイルが送られてきます。
- データに問題があった時のためにこのファイルを取り込む処理時間は1時間以内に完了することが必要。

## Prerequisite

念頭におく思想

### 人は間違える
- 当たり前と言えば当たり前ですが、まず人が作っている以上、システムは間違えることがあります。
- これは自分もそうだし、先方のシステムもそうです。
- そのため、前提として「データは必ずどこかにミスがある」ことを踏まえて設計し、ミスを安全に排除できるようにしておく必要があります。

### 直観に裏付けられた恐怖は正しい
- ここでいう「直観」は、論理的な証明ではなく、経験に裏付けられた危機感を指します。
- ソフトウェアエンジニアにとって恐怖は設計時に重要です。潜在的な危険を察知するセンサーとして働きます。
- 特に一度投入したら戻せないバッチ処理においては、「怖いと感じる箇所」こそ丁寧に設計する価値があります。

### 問題があったら安全に倒す
- 治療よりも予防が重要

## 設計に至るまでの経験

### 綺麗なデータは存在しない
- データ連携においても、内部ですら誤ったデータが流れてくるケースがありました。
- よって、怪しいデータは確実に排除する仕組みが必要であり、それを事前に想定しておくのが現実的な態度です。

### 冪等性の担保
- 過去にデータエンジニアとして働いていた際、リトライ可能なバッチとそうでないものの運用負荷の差を強く感じました。
- 一度失敗したとしても、再実行時に正しく状態を整合できるように設計しておくことは、将来の保守性と信頼性を大きく左右します。
- 冪等性を担保できたことで、運用者やQAチームからの信頼も厚くなりました。

### 外部連携の難易度

- 内部でもいろいろ問題が起きるのに対して外部の場合はより難易度が高くなる。
  - コミュニケーション、仕様漏れ

## High-level Design

- 通常のシステムであれば、ユーザー単位やレコード単位で逐次処理をすることが一般的です。
- しかし本件では並列性と安全性の両立が必要だったため、すべてのデータを「フェーズ」ごとに分離しました。
  - 全データに対して「前処理 → バリデーション → データ投入」の順で全件処理を完了するまで、次のフェーズに進まない設計にしています。
  - これは、エラーを起こすことよりも誤ったデータを取り込むことがより危険である

## Design Deep Dive

### 前処理
- duckdb を用いてCSVを取り込み、処理単位（例えばシャードやID範囲）ごとに分割。
- その結果を並列処理可能な単位として分配。

### バリデーション
- 明確な仕様違反はデータが誤っているので、その場で止めます
- 結果を cache しておきます

### データ投入
- バリデーションを通過したデータのみを投入します。
- ただし、validation通過から投入までの間に対象データが変化する可能性（例：ユーザー統合、削除）もあるため、投入時に必要なロック・整合チェックを行います。
- 基本はバリデーションが通過したので、データが投入されることになりますが、ここでも冪等を担保しています。
  - このあたりは QA での検証の難易度が高いので、unittest でがんじがらめになるように信頼性を高めています

## トレードオフと判断理由

### Reverse ETL vs 単一バッチ処理
- 当初は、DWHで使われるReverse ETL的アーキテクチャを検討しました。
- しかし、以下の理由により単一バッチ構成としました：
  - QAチームが複数の中間テーブルを検証するのが現実的でない
  - Validationをどこで行うか問題（最終的にはどこかが責任を持たなければならない）
  - DWHはinfraチームの所管であり、構築コストと権限面の制約がある
  - 正直 DWH という重厚なものを作らなくても duckdb で十分必要な前処理を行うことができる

### 実装の複雑さ
- 並列処理の前段階として、ID分割・中間管理構造などの実装を新規に行う必要がありました。
- Validationルールの形式化も一筋縄ではいかず、数多くの仕様とにらめっこしながらの設計となりました。
- データ投入時の状態変化への考慮も必要で、ここは最も複雑でかつ責任の重い箇所となっています。

## 結果として

### 並列化の効果
- 当初の目標は「1時間以内に完了すること」でしたが、現在はおおむね5分程度で完了しています。
- 設計段階で十分なスケーラビリティを確保したことで、将来的なデータ増加にも耐えられる構成になっています。

### 実際に運用して
- 運用中、実際に先方から誤ったデータが送信されたことがありました。
- それを事前にバリデーションで確実に排除できたことで、誤ったデータを取り込む自体を防げた事象となりました。
- この設計が功を奏した具体的な成功例となり、むしろ安心できた

## まとめ・今後の展望

本バッチ処理設計は、私自身が「怖い」と感じたポイントを出発点に構築したものです。  
その感覚は決して感情論ではなく、過去の失敗や運用課題から培われた直観でした。
